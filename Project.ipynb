{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import KFold\n",
    "from factor_analyzer import factor_analyzer, FactorAnalyzer\n",
    "from sklearn.decomposition import PCA\n",
    "import import_ipynb\n",
    "import SplitData as SD\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pdfkit as pdf\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for file_name in os.listdir('./New_Data/'):\n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    name = file_name.replace('.csv', '')\n",
    "    path = './New_Data/' + file_name\n",
    "    inputs[name] = pd.read_csv(path, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.splitActivities(inputs)\n",
    "SD.splitAudio(inputs)\n",
    "SD.splitDark(inputs)\n",
    "SD.splitConversation(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for file_name in os.listdir('./Final_Data/'):\n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    name = file_name.replace('.csv', '')\n",
    "    path = './Final_Data/' + file_name\n",
    "    df = pd.read_csv(path, index_col = 0)\n",
    "    inputs[name]= df.replace(0, np.nan)\n",
    "inputs['sms'] = inputs.pop('sms_spark')\n",
    "inputs['call_log'] = inputs.pop('call_log_spark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissing(df):\n",
    "    df = df.transpose().interpolate(method='linear').transpose()\n",
    "    return df.transpose().interpolate(method = 'linear', limit_direction='backward').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inputs.keys():\n",
    "    if inputs[key].shape[1] != 1:\n",
    "        inputs[key] = fillMissing(inputs[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into positive negative and flourishing score dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "flourishing = pd.read_csv('./StudentLife_Dataset/Outputs/FlourishingScale.csv')\n",
    "panas = pd.read_csv('./StudentLife_Dataset/Outputs/panas.csv')\n",
    "positive_score=['uid', 'Interested', 'Strong', 'Enthusiastic', 'Proud', 'Alert', 'Inspired', 'Determined ', 'Attentive', 'Active ']\n",
    "negative_score=['uid', 'Distressed', 'Upset', 'Guilty', 'Scared', 'Hostile ', 'Irritable','Nervous', 'Jittery', 'Afraid ']\n",
    "df_flour_post = pd.DataFrame()\n",
    "df_pos_post = pd.DataFrame()\n",
    "df_neg_post = pd.DataFrame()\n",
    "   \n",
    "for i in range(60):\n",
    "    temp_flour_post = (flourishing.loc[flourishing['uid'] == 'u' + str(f\"{i:02d}\")].loc[flourishing['type'] == 'post']).drop(columns='type')\n",
    "    df_flour_post = pd.concat([df_flour_post, temp_flour_post], axis = 0)\n",
    "    \n",
    "    temp_post = panas.loc[panas['uid'] == 'u' + str(f\"{i:02d}\")].loc[panas['type'] == 'post']\n",
    "    df1_post = temp_post[positive_score]\n",
    "    df2_post = temp_post[negative_score]\n",
    "    df_pos_post = pd.concat([df_pos_post, df1_post], axis=0)\n",
    "    df_neg_post = pd.concat([df_neg_post, df2_post], axis=0)\n",
    "df_flour_post = df_flour_post.set_index(keys='uid')\n",
    "df_pos_post = df_pos_post.set_index(keys='uid')\n",
    "df_neg_post = df_neg_post.set_index(keys = 'uid')\n",
    "df_flour_post = df_flour_post.dropna()\n",
    "df_pos_post = df_pos_post.dropna()\n",
    "df_neg_post = df_neg_post.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT DATA for Flourishing Data###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for people quit for post flourishing score testing ##\n",
    "full_ids = []\n",
    "for i in range(60):\n",
    "    full_ids.append('u' + str(f\"{i:02d}\"))\n",
    "ids_flour_post = df_flour_post.index.to_numpy()\n",
    "quit_ids = list(set(full_ids) - set(ids_flour_post))\n",
    "#print(quit_ids)\n",
    "### Delete people quit, from dataframe ###\n",
    "input_keys = inputs.keys()\n",
    "flour_input = {}\n",
    "for key in input_keys:\n",
    "    flour_input[key] = inputs[key].drop(quit_ids, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### 3 dimensional Data with (number of participants * number of weeks * number of features) ###\n",
    "# nWeeks = 10\n",
    "# input_keys = ['walk','run', 'noise', 'conversation_freq', 'conversation_time', 'dark_freq', 'dark_time']\n",
    "# n_features = len(input_keys)\n",
    "# data_3d = np.zeros((len(ids_flour_post), nWeeks, n_features))\n",
    "# for nWeek in range(10):\n",
    "#     n = 0\n",
    "#     for key in input_keys:\n",
    "#         data_3d[:, nWeek , n] = flour_input[key].iloc[:, nWeek]\n",
    "#         n += 1\n",
    "        \n",
    "        \n",
    "# file = open('data_y.pickle', 'wb')\n",
    "# pickle.dump(np_df, file)\n",
    "# file.close()\n",
    "\n",
    "# file2 = open('data_x.pickle', 'wb')\n",
    "# pickle.dump(data_3d, file2)\n",
    "# file2.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINARIZATION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert score to binary data ###\n",
    "def binarize(df, threshold):\n",
    "    m = threshold\n",
    "    if m < 1:\n",
    "        df[df.iloc[:, 0] > m] = 1\n",
    "        df[df.iloc[:, 0] <= m] = 0\n",
    "    else:\n",
    "        df[df.iloc[:, 0] <= m] = 0\n",
    "        df[df.iloc[:, 0] > m] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = os.getcwd()\n",
    "save_path = basic + \"/bilstm_params.pkl\"\n",
    "data_path = basic + \"/data_x.pickle\"\n",
    "label_path = basic + \"/data_y.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(data_path, \"rb\"))\n",
    "label = pickle.load(open(label_path, \"rb\")).reshape(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10               # train the training data n times\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_SIZE = 16\n",
    "TIME_STEP = data.shape[1]         # rnn time step / image height\n",
    "INPUT_SIZE = data.shape[2]         # rnn input size / image width\n",
    "LR = 0.01               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(data, label, train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(999)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "train_x, train_y = torch.from_numpy(train_x), torch.from_numpy(train_y)\n",
    "valid_x, valid_y = torch.from_numpy(valid_x), torch.from_numpy(valid_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=TensorDataset(train_x, train_y), \n",
    "                                           batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BiRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, num_layers=1, num_classes=2):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(INPUT_SIZE, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "        self.hidden = None\n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, self.hidden = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BiRNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all rnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "f = plt.figure(figsize=(12, 5))\n",
    "ax1 = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.float())                       # batch x\n",
    "        b_y = Variable(y.long())                        # batch y\n",
    "        output = rnn(b_x)                            # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "        if step % 5 == 0:\n",
    "            valid_output = rnn(Variable(valid_x.float()))\n",
    "            train_output = rnn(Variable(train_x.float()))\n",
    "            train_loss = loss_func(train_output, train_y.long())\n",
    "            valid_loss = loss_func(valid_output, valid_y.long())\n",
    "            train_losses.append(train_loss.data)\n",
    "            valid_losses.append(valid_loss.data)\n",
    "            \n",
    "            pred_train = torch.max(train_output, 1)[1].data.numpy().squeeze()\n",
    "            pred_valid = torch.max(valid_output, 1)[1].data.numpy().squeeze()\n",
    "            train_accu = sum(pred_train == train_y.data.numpy()) / float(train_y.numpy().size)\n",
    "            valid_accu = sum(pred_valid == valid_y.data.numpy()) / float(valid_y.numpy().size)\n",
    "            train_accuracy.append(train_accu)\n",
    "            valid_accuracy.append(valid_accu)\n",
    "            \n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data, '| valid loss: %.4f' % valid_loss.data, \n",
    "                  '| train accuracy: %.4f' % train_accu, '| valid accuracy: %.4f' % valid_accu)\n",
    "\n",
    "ax1.plot(train_losses, label=\"train loss\")\n",
    "ax1.plot(valid_losses, label=\"valid loss\")\n",
    "ax1.legend()\n",
    "ax2.plot(train_accuracy, label=\"train acc\")\n",
    "ax2.plot(valid_accuracy, label=\"valid acc\")\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Hidden Gate from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHidden():\n",
    "    rnn_knn = BiRNN()\n",
    "    optimizer = torch.optim.Adam(rnn_knn.parameters(), lr=LR)   # optimize all rnn parameters\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "    # training and testing\n",
    "    for epoch in range(EPOCH):\n",
    "        data1 = torch.tensor(data)\n",
    "        y1 = torch.tensor(label)\n",
    "        b_x = Variable(data1.float())                       # batch x\n",
    "        b_y = Variable(y1.long())                        # batch y\n",
    "        output = rnn_knn(b_x)                            # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "    data_week10 = rnn_knn.hidden[1][0]\n",
    "    data_week10 = data_week10.detach().numpy()\n",
    "    return data_week10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for people quit for post flourishing score testing ##\n",
    "full_ids = []\n",
    "for i in range(60):\n",
    "    full_ids.append('u' + str(f\"{i:02d}\"))\n",
    "ids_flour_post = df_flour_post.index.to_numpy()\n",
    "quit_ids = list(set(full_ids) - set(ids_flour_post))\n",
    "\n",
    "### Delete people quit, from dataframe ###\n",
    "input_keys = inputs.keys()\n",
    "flour_input = {}\n",
    "for key in input_keys:\n",
    "    flour_input[key] = inputs[key].drop(quit_ids, errors='ignore')\n",
    "for key in flour_input.keys():\n",
    "    flour_input[key] = flour_input[key].sum(axis=1).to_frame()\n",
    "X_flour = pd.DataFrame(columns=None)\n",
    "\n",
    "## input and label for flourishing score\n",
    "for key in flour_input:\n",
    "    flour_input[key].columns = [key]\n",
    "    X_flour = pd.concat([X_flour, flour_input[key]], axis = 1)\n",
    "label_flour = binarize(df_flour_post.sum(axis = 1).to_frame(0), 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for people quit for post flourishing score testing ##\n",
    "full_ids = []\n",
    "for i in range(60):\n",
    "    full_ids.append('u' + str(f\"{i:02d}\"))\n",
    "ids_pos_post = df_pos_post.index.to_numpy()\n",
    "quit_ids = list(set(full_ids) - set(ids_pos_post))\n",
    "\n",
    "### Delete people quit, from dataframe ###\n",
    "input_keys = inputs.keys()\n",
    "pos_input = {}\n",
    "for key in input_keys:\n",
    "    pos_input[key] = inputs[key].drop(quit_ids, errors='ignore')\n",
    "for key in pos_input.keys():\n",
    "    pos_input[key] = pos_input[key].sum(axis=1).to_frame()\n",
    "X_pos = pd.DataFrame(columns=None)\n",
    "\n",
    "## input and label for flourishing score\n",
    "for key in pos_input:\n",
    "    pos_input[key].columns = [key]\n",
    "    X_pos = pd.concat([X_pos, pos_input[key]], axis = 1)\n",
    "label_pos = binarize(df_pos_post.sum(axis = 1).to_frame(0), 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for people quit for post flourishing score testing ##\n",
    "full_ids = []\n",
    "for i in range(60):\n",
    "    full_ids.append('u' + str(f\"{i:02d}\"))\n",
    "ids_neg_post = df_neg_post.index.to_numpy()\n",
    "quit_ids = list(set(full_ids) - set(ids_neg_post))\n",
    "\n",
    "### Delete people quit, from dataframe ###\n",
    "input_keys = inputs.keys()\n",
    "neg_input = {}\n",
    "for key in input_keys:\n",
    "    neg_input[key] = inputs[key].drop(quit_ids, errors='ignore')\n",
    "for key in pos_input.keys():\n",
    "    neg_input[key] = neg_input[key].sum(axis=1).to_frame()\n",
    "X_neg = pd.DataFrame(columns=None)\n",
    "\n",
    "## input and label for flourishing score\n",
    "for key in neg_input:\n",
    "    neg_input[key].columns = [key]\n",
    "    X_neg = pd.concat([X_neg, neg_input[key]], axis = 1)\n",
    "label_neg = binarize(df_neg_post.sum(axis = 1).to_frame(0), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(features, y, n_neighbour):\n",
    "    train_score = pd.DataFrame()\n",
    "    valid_score = pd.DataFrame()\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train, test in kf.split(features):\n",
    "        X_train, X_test, y_train, y_test = features[train, :], features[test, :], y[train], y[test]\n",
    "        neighbour = KNeighborsClassifier(n_neighbors=n_neighbour).fit(X_train, y_train)\n",
    "        pred_test = neighbour.predict(X_test)\n",
    "        pred_train = neighbour.predict(X_train)\n",
    "        auc_train = 0\n",
    "        acc_train = 0\n",
    "        precision_train = 0\n",
    "        recall_train = 0\n",
    "        fscore_train = 0\n",
    "        auc_test = 0\n",
    "        acc_test = 0\n",
    "        precision_test = 0\n",
    "        recall_test = 0\n",
    "        fscore_test = 0\n",
    "        try:\n",
    "            auc_test = roc_auc_score(y_test, pred_test)\n",
    "            acc_test = accuracy_score(y_test, pred_test)\n",
    "            precision_test, recall_test, fscore_test, _ = precision_recall_fscore_support(y_test, pred_test, average='weighted')\n",
    "            auc_train = roc_auc_score(y_train,  pred_train)\n",
    "            acc_train = accuracy_score(y_train, pred_train)\n",
    "            precision_train, recall_train, fscore_train, _ = precision_recall_fscore_support(y_train, pred_train, average='weighted')\n",
    "        except ValueError:\n",
    "            print('error')\n",
    "            continue\n",
    "            # _, _, _, _, roc_auc = KNN(features, y, n_neighbour)\n",
    "            # acc, _, _, _, _ = KNN(features, y, n_neighbour)\n",
    "            # _, precision, recall, fscore, _ =KNN(features, y, n_neighbour)\n",
    "        score_train = np.array([acc_train, precision_train, recall_train, fscore_train, auc_train])\n",
    "        score_test = np.array([acc_test, precision_test, recall_test, fscore_test, auc_test])    \n",
    "    #temp = pd.DataFrame(data = {'Accuracy': acc, 'Precision': precision, 'Recall': recall, 'F1': fscore, 'ROC_AUC': roc_auc})\n",
    "        score_train = pd.DataFrame(score_train.reshape(-1, len(score_train)), columns=['accuracy', 'precision', 'recall', 'fscore', 'roc_auc'])\n",
    "        score_test = pd.DataFrame(score_test.reshape(-1, len(score_test)), columns=['accuracy', 'precision', 'recall', 'fscore', 'roc_auc'])\n",
    "        valid_score = pd.concat([valid_score, score_test], axis=0)\n",
    "        train_score = pd.concat([train_score, score_train], axis=0)\n",
    "    return train_score, valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC and AUC to find the optimal k ###\n",
    "def roc_auc_comparison(features, y):\n",
    "    n = 4\n",
    "    kf = KFold(n_splits=n, shuffle=True)\n",
    "    scores = []\n",
    "    for i in range(2,10):\n",
    "        score = 0\n",
    "        n = 0\n",
    "        for train, test in kf.split(features):\n",
    "            X_train, X_test, y_train, y_test = features[train, :], features[test, :], y[train], y[test]\n",
    "            model = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n",
    "            pred = model.predict_proba(X_test)[:,1]\n",
    "            try:\n",
    "                score += roc_auc_score(y_test, pred)\n",
    "                n += 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "        scores.append(score/n)\n",
    "    n_neighbour = np.asarray(scores).argmax()+2\n",
    "    plt.plot(range(2,10),scores,label='AUC_score',color='grey')\n",
    "    plt.xlabel('number of neighbours')\n",
    "    plt.ylabel('AUC score')\n",
    "    return n_neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_feature_selection(X, label, name):\n",
    "    count = [0] *len(X.columns)\n",
    "    for i in range(100):\n",
    "        model = RandomForestClassifier()\n",
    "        rfe = RFE(model)\n",
    "        rfe = rfe.fit(X, label)\n",
    "        a = rfe.support_ \n",
    "\n",
    "        X_new = rfe.transform(X)\n",
    "        X_new = pd.DataFrame(X_new, index = X.index, columns=X.columns[a])\n",
    "        n = roc_auc_comparison(features=X_new.to_numpy(), y=label.to_numpy())\n",
    "        acc, _, _, _, _ = KNN(X_new, y=label, n_neighbour=n)\n",
    "        if acc <= 0.5:\n",
    "            continue\n",
    "        for j in range(len(rfe.ranking_)):\n",
    "            if rfe.ranking_[j] == 1:\n",
    "                count[j] += 1\n",
    "    plt.show()\n",
    "    temp = pd.DataFrame(count, index = X.columns, columns=['freq']).sort_values(by = ['freq'], ascending=False)\n",
    "    plt.barh(temp.index, temp.iloc[:,0])\n",
    "    title = 'Feature Importance for ' + name + ' score in KNN'\n",
    "    plt.title(title)\n",
    "    path = './Images/knn_importance_' + name + '.png'\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return np.array(count).argsort()[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flourishing score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = ['conversation_time', 'noise', 'run', 'walk', 'social']\n",
    "#chosen = ['conversation_time', 'noise', 'run']\n",
    "X_flour_chosen = X_flour.loc[:, chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "train\n",
      "0.8148148148148148\n",
      "test\n",
      "0.2\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.7777777777777778\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.2222222222222222\n",
      "iteration 1\n",
      "train\n",
      "0.7407407407407407\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 2\n",
      "train\n",
      "0.7037037037037037\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.5357142857142857\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.6666666666666666\n",
      "iteration 3\n",
      "train\n",
      "0.7037037037037037\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.7857142857142857\n",
      "test\n",
      "0.2222222222222222\n",
      "iteration 4\n",
      "train\n",
      "0.7407407407407407\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.3333333333333333\n",
      "iteration 5\n",
      "train\n",
      "0.6296296296296297\n",
      "test\n",
      "0.4\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.8888888888888888\n",
      "train\n",
      "0.5\n",
      "test\n",
      "0.7777777777777778\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 6\n",
      "train\n",
      "0.6296296296296297\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.2222222222222222\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 7\n",
      "train\n",
      "0.7037037037037037\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.3333333333333333\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.3333333333333333\n",
      "iteration 8\n",
      "train\n",
      "0.7037037037037037\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.2222222222222222\n",
      "train\n",
      "0.7142857142857143\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 9\n",
      "train\n",
      "0.5925925925925926\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.3333333333333333\n",
      "iteration 10\n",
      "train\n",
      "0.6296296296296297\n",
      "test\n",
      "0.4\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.7142857142857143\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.6666666666666666\n",
      "iteration 11\n",
      "train\n",
      "0.7407407407407407\n",
      "test\n",
      "0.4\n",
      "train\n",
      "0.5357142857142857\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 12\n",
      "train\n",
      "0.5925925925925926\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.7142857142857143\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 13\n",
      "train\n",
      "0.5925925925925926\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.3333333333333333\n",
      "train\n",
      "0.75\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.7142857142857143\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 14\n",
      "train\n",
      "0.6666666666666666\n",
      "test\n",
      "0.4\n",
      "train\n",
      "0.6071428571428571\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.5555555555555556\n",
      "iteration 15\n",
      "train\n",
      "0.5555555555555556\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.5714285714285714\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 16\n",
      "train\n",
      "0.6666666666666666\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.5357142857142857\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 17\n",
      "train\n",
      "0.6296296296296297\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.5555555555555556\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.75\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 18\n",
      "train\n",
      "0.7407407407407407\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.6666666666666666\n",
      "train\n",
      "0.75\n",
      "test\n",
      "0.3333333333333333\n",
      "train\n",
      "0.5357142857142857\n",
      "test\n",
      "0.3333333333333333\n",
      "iteration 19\n",
      "train\n",
      "0.7407407407407407\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.4642857142857143\n",
      "test\n",
      "0.8888888888888888\n",
      "train\n",
      "0.6428571428571429\n",
      "test\n",
      "0.4444444444444444\n",
      "train\n",
      "0.6785714285714286\n",
      "test\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#gnb.fit(X_train, y_train)\n",
    "for i in range(20):\n",
    "    kf = KFold(n_splits=4, shuffle = True)\n",
    "    print('iteration', i)\n",
    "    for train, test in kf.split(X_flour_chosen):\n",
    "        X = X_flour_chosen.to_numpy()\n",
    "        y = label_flour.to_numpy()\n",
    "        X_train, X_test, y_train, y_test = X[train, :], X[test, :], y[train], y[test]\n",
    "        gnb = gnb.fit(X_train, y_train)\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        y_train_pred = gnb.predict(X_train)\n",
    "        print('train')\n",
    "        print(accuracy_score(y_train, y_train_pred))\n",
    "        print('test')\n",
    "        print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chosen = ['conversation_time', 'conversation_freq', 'noise']\n",
    "#chosen = ['conversation_time', 'conversation_freq']\n",
    "X_pos_chosen = X_pos.loc[:, chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#gnb.fit(X_train, y_train)\n",
    "for i in range(20):\n",
    "    kf = KFold(n_splits=4, shuffle = True)\n",
    "    print('iteration', i)\n",
    "    for train, test in kf.split(X_pos_chosen):\n",
    "        X = X_pos_chosen.to_numpy()\n",
    "        y = label_pos.to_numpy()\n",
    "        X_train, X_test, y_train, y_test = X[train, :], X[test, :], y[train], y[test]\n",
    "        gnb = gnb.fit(X_train, y_train)\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        y_train_pred = gnb.predict(X_train)\n",
    "        print('train')\n",
    "        print(accuracy_score(y_train, y_train_pred))\n",
    "        print('test')\n",
    "        print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = ['dark_time', 'noise', 'dark_freq', 'run', 'sms']\n",
    "X_neg_chosen = X_neg.loc[:, chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "train\n",
      "0.6896551724137931\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.8666666666666667\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 1\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.8620689655172413\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7\n",
      "test\n",
      "0.5555555555555556\n",
      "iteration 2\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.8\n",
      "test\n",
      "0.5555555555555556\n",
      "iteration 3\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 4\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 5\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.3\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 6\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.8\n",
      "test\n",
      "0.6666666666666666\n",
      "iteration 7\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.6896551724137931\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 9\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 10\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.6333333333333333\n",
      "test\n",
      "0.6666666666666666\n",
      "iteration 11\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.8620689655172413\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7\n",
      "test\n",
      "0.8888888888888888\n",
      "iteration 12\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7333333333333333\n",
      "test\n",
      "0.8888888888888888\n",
      "iteration 13\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.8888888888888888\n",
      "iteration 14\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.8\n",
      "test\n",
      "0.5555555555555556\n",
      "iteration 15\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.8\n",
      "test\n",
      "0.2222222222222222\n",
      "iteration 16\n",
      "train\n",
      "0.8620689655172413\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.6896551724137931\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.5555555555555556\n",
      "iteration 17\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7666666666666667\n",
      "test\n",
      "0.7777777777777778\n",
      "iteration 18\n",
      "train\n",
      "0.6896551724137931\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.7241379310344828\n",
      "test\n",
      "0.9\n",
      "train\n",
      "0.8275862068965517\n",
      "test\n",
      "0.5\n",
      "train\n",
      "0.7333333333333333\n",
      "test\n",
      "0.4444444444444444\n",
      "iteration 19\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.8\n",
      "train\n",
      "0.7586206896551724\n",
      "test\n",
      "0.7\n",
      "train\n",
      "0.7931034482758621\n",
      "test\n",
      "0.6\n",
      "train\n",
      "0.7333333333333333\n",
      "test\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#gnb.fit(X_train, y_train)\n",
    "for i in range(20):\n",
    "    kf = KFold(n_splits=4, shuffle = True)\n",
    "    print('iteration', i)\n",
    "    for train, test in kf.split(X_neg_chosen):\n",
    "        X = X_neg_chosen.to_numpy()\n",
    "        y = label_neg.to_numpy()\n",
    "        X_train, X_test, y_train, y_test = X[train, :], X[test, :], y[train], y[test]\n",
    "        gnb = gnb.fit(X_train, y_train)\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        y_train_pred = gnb.predict(X_train)\n",
    "        print('train')\n",
    "        print(accuracy_score(y_train, y_train_pred))\n",
    "        print('test')\n",
    "        print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flourishing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = pd.DataFrame(columns = None)\n",
    "optimalK = []\n",
    "for i in range(100):\n",
    "    n = roc_auc_comparison(X_flour_chosen.to_numpy(), label_flour.to_numpy())\n",
    "    optimalK.append(n)\n",
    "    li = KNN(X_flour_chosen.to_numpy(), label_flour.to_numpy(), n)\n",
    "    score = pd.concat([score, pd.DataFrame(np.array(li))], axis=1)\n",
    "plt.title('Find Optimal K for KNN for predicting Flourishing Score')\n",
    "plt.savefig('./Images/k_flour.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "temp = np.unique(np.array(optimalK),return_counts=True)\n",
    "index = temp[0]\n",
    "freq = temp[1]\n",
    "#index, freq\n",
    "plt.barh(index , freq)\n",
    "plt.title('Frequency of each K selected to be an optimal for Flourishing Score in KNN')\n",
    "plt.ylabel('K')\n",
    "plt.xlabel('frequency')\n",
    "path = './Images/knn_optimalK_four.png'\n",
    "plt.savefig(path, bbox_inches='tight')\n",
    "plt.show()\n",
    "score.index = ['acc', 'precision', 'recall', 'fscore', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = score.mean(axis = 1).to_frame()\n",
    "temp.columns = ['Score for Flourishing']\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame(columns = None)\n",
    "optimalK = []\n",
    "for i in range(100):\n",
    "    n = roc_auc_comparison(X_pos_chosen.to_numpy(), label_pos.to_numpy())\n",
    "    optimalK.append(n)\n",
    "    li = KNN(X_pos_chosen.to_numpy(), label_pos.to_numpy(), n)\n",
    "    score = pd.concat([score, pd.DataFrame(np.array(li))], axis=1)\n",
    "plt.title('Find Optimal K for KNN for predicting Positive Score')\n",
    "plt.savefig('./Images/k_positive.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "temp = np.unique(np.array(optimalK),return_counts=True)\n",
    "index = temp[0]\n",
    "freq = temp[1]\n",
    "#index, freq\n",
    "plt.barh(index , freq)\n",
    "plt.title('Frequency of each K selected to be an optimal for Positive Score in KNN')\n",
    "plt.ylabel('K')\n",
    "plt.xlabel('frequency')\n",
    "path = './Images/knn_optimalK_pos.png'\n",
    "plt.savefig(path, bbox_inches='tight')\n",
    "plt.show()\n",
    "score.index = ['acc', 'precision', 'recall', 'fscore', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = score.mean(axis = 1).to_frame()\n",
    "temp.columns = ['Score for PANAS Positive']\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame(columns = None)\n",
    "optimalK = []\n",
    "for i in range(100):\n",
    "    n = roc_auc_comparison(X_neg_chosen.to_numpy(), label_neg.to_numpy())\n",
    "    optimalK.append(n)\n",
    "    li = KNN(X_neg_chosen.to_numpy(), label_neg.to_numpy(), n)\n",
    "    score = pd.concat([score, pd.DataFrame(np.array(li))], axis=1)\n",
    "    \n",
    "    \n",
    "plt.title('Find Optimal K for KNN for predicting Negative Score')\n",
    "plt.savefig('./Images/k_negative.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "temp = np.unique(np.array(optimalK),return_counts=True)\n",
    "index = temp[0]\n",
    "freq = temp[1]\n",
    "#index, freq\n",
    "plt.barh(index , freq)\n",
    "plt.title('Frequency of each K selected to be an optimal for Negative Score in KNN')\n",
    "plt.ylabel('K')\n",
    "plt.xlabel('frequency')\n",
    "path = './Images/knn_optimalK_neg.png'\n",
    "plt.savefig(path, bbox_inches='tight')\n",
    "plt.show()\n",
    "score.index = ['acc', 'precision', 'recall', 'fscore', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = score.mean(axis = 1).to_frame()\n",
    "temp.columns = ['Score for PANAS Negative']\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_forest_validation(X, y, name, rang, score_type):\n",
    "    train_score, validation_score = validation_curve(RandomForestClassifier(), X, y.to_numpy().ravel(), param_name=name,param_range=rang, scoring=\"accuracy\", cv=3)\n",
    "    sum_score = validation_score.sum(axis = 1)\n",
    "    # Calculate mean and standard deviation for training set scores\n",
    "    train_mean = np.mean(train_score, axis=1)\n",
    "    train_std = np.std(train_score, axis=1)\n",
    "\n",
    "    # Calculate mean and standard deviation for test set scores\n",
    "    validation_mean = np.mean(validation_score, axis=1)\n",
    "    validation_std = np.std(validation_score, axis=1)\n",
    "\n",
    "    # Plot mean accuracy scores for training and test sets\n",
    "    plt.plot(rang, train_mean, label=\"Training score\", color=\"red\")\n",
    "    plt.plot(rang, validation_mean, label=\"Cross-validation score\", color=\"blue\")\n",
    "\n",
    "    # Plot accurancy bands for training and test sets\n",
    "    plt.fill_between(rang, train_mean - train_std, train_mean + train_std, color=\"pink\")\n",
    "    plt.fill_between(rang, validation_mean - validation_std, validation_mean + validation_std, color=\"lightblue\")\n",
    "    n = sum_score.argmax()\n",
    "    print(sum_score[n])\n",
    "    \n",
    "    # Create plot\n",
    "    title = \"Validation Curve With Random Forest for \" + score_type\n",
    "    plt.title(title)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc=\"best\")\n",
    "    path = './Images/' + name + '_' + score_type + '.png'\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return rang[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseRandomForest(X, label, score_type):\n",
    "    rang = np.arange(1, 100, 2)\n",
    "    name = \"n_estimators\"\n",
    "    n_estimators = random_forest_validation(X, label, name, rang, score_type)\n",
    "    rang = np.arange(2, 10, 1)\n",
    "    name = \"max_depth\"\n",
    "    max_depth = random_forest_validation(X, label, name, rang, score_type)\n",
    "    rang = np.arange(2, 10, 1)\n",
    "    name = \"min_samples_split\"\n",
    "    min_samples_split = random_forest_validation(X, label,name, rang, score_type)\n",
    "    rang = np.arange(2, 10, 1)\n",
    "    name = \"min_samples_leaf\"\n",
    "    min_samples_leaf = random_forest_validation(X, label,name, rang, score_type)\n",
    "    return n_estimators, max_depth, min_samples_split, min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flourishing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators, max_depth, min_samples_split, min_samples_leaf = optimiseRandomForest(X_flour, label_flour, 'flour')\n",
    "X_flour_train, X_flour_valid, label_flour_train, label_flour_valid =  train_test_split(X_flour, label_flour, train_size=0.8)\n",
    "print(n_estimators, max_depth, min_samples_split, min_samples_leaf)\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf = min_samples_leaf)\n",
    "clf.fit(X_flour_train, label_flour_train)\n",
    "importance = clf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index = X_flour.columns.to_numpy())\n",
    "importance.columns = ['importance']\n",
    "importance = importance.sort_values(by = ['importance'], ascending=False)\n",
    "plt.barh(importance.index, importance.iloc[:, 0])\n",
    "plt.title('Feature Importance for Flourishing Score')\n",
    "plt.xlabel('importance rate')\n",
    "plt.savefig('./Images/random_importance_flour.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_flour_valid)\n",
    "acc = accuracy_score(label_flour_valid, pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(label_flour_valid, pred, average='weighted')\n",
    "auc = roc_auc_score(label_flour_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([acc, precision, recall, fscore, auc]), index = ['accuracy', 'precision', 'recall', 'fscore', 'auc'], columns = ['Scores for Flourishing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Optimisation ###\n",
    "X_pos_train, X_pos_valid, label_pos_train, label_pos_valid =  train_test_split(X_pos, label_pos, train_size=0.8)\n",
    "n_estimators, max_depth, min_samples_split, min_samples_leaf = optimiseRandomForest(X_pos, label_pos, 'positive')\n",
    "\n",
    "print(n_estimators, max_depth, min_samples_split, min_samples_leaf)\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf = min_samples_leaf, random_state=0)\n",
    "clf.fit(X_pos_train, label_pos_train)\n",
    "importance = clf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index = X_pos_train.columns.to_numpy())\n",
    "importance.columns = ['importance']\n",
    "importance = importance.sort_values(by = ['importance'], ascending=False)\n",
    "plt.barh(importance.index, importance.iloc[:, 0])\n",
    "plt.title('Feature Importance for Positive Score')\n",
    "plt.xlabel('importance rate')\n",
    "plt.savefig('./Images/random_importance_positive.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_pos_valid)\n",
    "acc = accuracy_score(label_pos_valid, pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(label_pos_valid, pred, average='weighted')\n",
    "auc = roc_auc_score(label_pos_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([acc, precision, recall, fscore, auc]), index = ['accuracy', 'precision', 'recall', 'fscore', 'auc'], columns = ['Scores for Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimisation ###\n",
    "X_neg_train, X_neg_valid, label_neg_train, label_neg_valid =  train_test_split(X_neg, label_neg, train_size=0.8)\n",
    "n_estimators, max_depth, min_samples_split, min_samples_leaf = optimiseRandomForest(X_neg, label_neg, 'negative')\n",
    "\n",
    "print(n_estimators, max_depth, min_samples_split, min_samples_leaf)\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf = min_samples_leaf, random_state=0)\n",
    "smt = SMOTE()\n",
    "X_neg_train, label_neg_train = smt.fit_sample(X_neg_train, label_neg_train)\n",
    "\n",
    "clf.fit(X_neg_train, label_neg_train)\n",
    "importance = clf.feature_importances_\n",
    "importance = pd.DataFrame(importance, index = X_neg.columns.to_numpy())\n",
    "importance.columns = ['importance']\n",
    "importance = importance.sort_values(by = ['importance'], ascending=False)\n",
    "plt.barh(importance.index, importance.iloc[:, 0])\n",
    "plt.title('Feature Importance for Negative Score')\n",
    "plt.savefig('./Images/random_importance_negative.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_neg_valid)\n",
    "acc = accuracy_score(label_neg_valid, pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(label_neg_valid, pred, average='weighted')\n",
    "auc = roc_auc_score(label_neg_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([acc, precision, recall, fscore, auc]), index = ['accuracy', 'precision', 'recall', 'fscore', 'auc'], columns = ['Scores for Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flourishing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_flour['dark_time']), label_flour], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_flour['conversation_time']), label_flour], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_flour['call_log']), label_flour], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_flour['noise']), label_flour], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_neg['dark_freq']), label_neg], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_neg['dark_time']), label_neg], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_neg['conversation_time']), label_neg], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(X_neg['walk']), label_neg], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in X_pos.keys():\n",
    "    a = pd.concat([pd.DataFrame(X_pos[key]), label_pos], axis = 1).corr()\n",
    "    path = './Images/' + key+'.html'\n",
    "    a.to_html(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
